{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW_JlzoVFYYL"
      },
      "source": [
        "# 3. INTRODUCCIÓN A FORMATOS DE DATOS: CSV, JSON, PARQUET, AVRO\n",
        "## 3.1 Introducción\n",
        "La programación básica en Python constituye el fundamento sobre el cual se construyen aplicaciones industriales y científicas. En el análisis y manipulación de datos, es común trabajar con diferentes formatos de archivos que almacenan información de manera estructurada. Cada formato tiene sus propias características, ventajas y casos de uso. En esta sección, exploraremos los formatos de datos más utilizados: CSV, JSON, Parquet y Avro, y aprenderemos cómo trabajar con ellos en Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1XafLIyFYYN"
      },
      "source": [
        "## 3.2 Tipos de Datos\n",
        "En el análisis de datos, es esencial identificar el tipo de datos con los que se está trabajando para seleccionar las herramientas y métodos más adecuados. Hay tres tipos de datos:\n",
        "- **Estructurados**: Organizados en formatos rígidos como tablas con filas y columnas, facilitando el almacenamiento y la consulta.\n",
        "- **Semi-estructurados**: Parcialmente organizados utilizando etiquetas o esquemas flexibles, lo que permite una mayor adaptabilidad al integrar información diversa.\n",
        "- **No estructurados**: No siguen un esquema predefinido y abarcan una amplia variedad de formatos, lo que los hace más complejos de gestionar pero altamente versátiles para capturar información rica y detallada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r08TishFYYN"
      },
      "source": [
        "## 3.3 CSV (Valores Separados por Comas)\n",
        "El formato CSV se caracteriza por su simplicidad y se utiliza ampliamente para almacenar datos tabulares en texto plano. En un archivo CSV, cada línea representa un registro y los campos están separados por comas (u otro delimitador). Es compatible con la mayoría de las aplicaciones y lenguajes de programación.\n",
        "Es un formato de datos estructurados que almacena información en tablas con filas y columnas, utilizando comas como delimitadores.\n",
        "Un ejemplo de un archivo CSV podría ser:\n",
        "\n",
        "```csv\n",
        "id,firstname,lastname,email,birthdate\n",
        "1,Kerry,O'Connell,Kerry16@gmail.com,1990-01-01\n",
        "2,Ethel,Miller,Ethel14@hotmail.com,1985-05-12\n",
        "3,Willie,Barton,Willie.Barton@gmail.com,1992-07-23\n",
        "4,Ellis,Lowe,Ellis.Lowe@gmail.com,1988-11-30\n",
        "5,Raymond,Miller,Raymond.Miller@gmail.com,1991-03-15\n",
        "6,Ellen,Thompson,Ellen92@hotmail.com,1987-09-25\n",
        "7,Joe,Rice,Joe55@gmail.com,1993-12-05\n",
        "8,Nathaniel,Legros,Nathaniel40@hotmail.com,1986-04-18\n",
        "9,Maxine,Schinner,Maxine93@hotmail.com,1990-08-22\n",
        "10,Tim,Jacobson,Tim92@hotmail.com,1989-10-10\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HxK1YS8FYYO"
      },
      "source": [
        "Para trabajar con archivos CSV, utilizaremos Pandas y el concepto de DataFrames, que se explicará en detalle en la siguiente sección de esta unidad.\n",
        "\n",
        "Primero, debemos asegurarnos de tener instalados los paquetes necesarios.\n",
        "\n",
        "```bash\n",
        "pip install pandas # En Windows\n",
        "pip3 install pandas # En macOS y Linux\n",
        "```\n",
        "\n",
        "Una vez instalados, podemos importarlos y utilizarlos para leer un archivo CSV utilizando la función `.read_csv()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2wfAGAvFYYP"
      },
      "outputs": [],
      "source": [
        "# Lectura con pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJKWjoceFYYQ"
      },
      "source": [
        "De manera similar, para escribir un archivo CSV, utilizaremos el DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLKYOknXFYYQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "# Escritura\n",
        "df.to_csv('datos_salida_pandas.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYoS28_PFYYR"
      },
      "source": [
        "Para CSV, hay numerosas opciones como elegir el delimitador, la codificación e incluso los índices que se pueden excluir al trabajar con Pandas. Además, puedes trabajar con archivos CSV utilizando el módulo nativo CSV en Python. Sin embargo, no es tan comúnmente utilizado y puede ser algo complejo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITtdoFjvFYYR"
      },
      "source": [
        "## 3.4 JSON (Notación de Objetos de JavaScript)\n",
        "JSON es un formato ligero de intercambio de datos que es fácil de leer y escribir. Es ideal para representar estructuras de datos complejas y anidadas, como objetos y arrays.\n",
        "Representa datos semi-estructurados utilizando una estructura de pares clave-valor, lo que permite una mayor flexibilidad en la organización de la información.\n",
        "Un ejemplo de JSON:\n",
        "\n",
        "```json\n",
        "{\"index\": {\"0\": 0, \"1\": 1},\n",
        "\"a\": {\"0\": 1, \"1\": null},\n",
        "\"b\": {\"0\": 2.5, \"1\": 4.5},\n",
        "\"c\": {\"0\": true, \"1\": false},\n",
        "\"d\": {\"0\": \"a\", \"1\": \"b\"},\n",
        "\"e\": {\"0\": 1577.2, \"1\": 1577.1}}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrWOqvwiFYYR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_json('data.json')\n",
        "display(df)\n",
        "# Escritura\n",
        "df.to_json('datos_salida_pandas.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qyPSD_PFYYR"
      },
      "source": [
        "Además, podemos trabajar directamente con el módulo nativo JSON en Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ9RA8C5FYYS"
      },
      "outputs": [],
      "source": [
        "# Uso del módulo JSON\n",
        "import json\n",
        "\n",
        "# Lectura\n",
        "with open('data.json') as f:\n",
        "    data = json.load(f)\n",
        "    print(data)\n",
        "\n",
        "# Escritura\n",
        "with open('datos_salida.json', 'w') as f:\n",
        "    json.dump(data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuS-TSmFYYS"
      },
      "source": [
        "## 3.5 Parquet\n",
        "Parquet es un formato de almacenamiento basado en columnas, diseñado para el procesamiento eficiente de grandes conjuntos de datos. Es especialmente útil en entornos de Big Data y cuando se trabaja con sistemas distribuidos como Hadoop o Spark.\n",
        "Soporta compresión y codificación eficientes, reduciendo el espacio de almacenamiento y mejorando el rendimiento de lectura. Esto lo hace ideal cuando se trabaja en entornos de Big Data.\n",
        "Además, tanto Parquet como Avro forman parte del ecosistema de Apache, facilitando la integración y compartiendo beneficios con otras tecnologías como Kafka, Hive o Spark.\n",
        "Para generar archivos Parquet visualmente para ejemplos, utilizaremos: [https://konbert.com/generator/parquet\n",
        "Para trabajar con ellos utilizando Pandas, necesitamos instalar el paquete `pyarrow`:\n",
        "\n",
        "```bash\n",
        "pip install pyarrow\n",
        "```\n",
        "\n",
        "Una vez instalada la dependencia, podemos trabajar con estos archivos de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMcDWIrhFYYS"
      },
      "outputs": [],
      "source": [
        "! conda install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOKo2RtCFYYS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_parquet('datos.parquet')\n",
        "display(df)\n",
        "\n",
        "# Escritura\n",
        "df.to_parquet('datos_salida_pandas.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGKvze6LFYYS"
      },
      "source": [
        "## 3.6 Avro\n",
        "Avro es un sistema de serialización de datos que utiliza esquemas definidos en JSON para representar estructuras de datos complejas en formato binario. Es ampliamente utilizado en sistemas de Big Data y streaming, como Apache Kafka. Avro facilita la interoperabilidad entre diferentes sistemas y lenguajes de programación.\n",
        "Se considera semi-estructurado debido a su capacidad de incluir un esquema que define la estructura de los datos, facilitando la serialización y deserialización eficiente.\n",
        "Un ejemplo de esquema podría ser:\n",
        "\n",
        "```python\n",
        "schema = {\n",
        "    'doc': 'documento Avro',\n",
        "    'name': 'Usuario',\n",
        "    'namespace': 'ejemplo.avro',\n",
        "    'type': 'record',\n",
        "    'fields': [\n",
        "        {'name': 'name', 'type': 'string'},\n",
        "        {'name': 'age', 'type': 'int'},\n",
        "        {'name': 'city', 'type': 'string'},\n",
        "    ],\n",
        "}\n",
        "```\n",
        "\n",
        "Al igual que Parquet, forma parte del ecosistema de Apache, facilitando la integración y compartiendo beneficios con otras tecnologías como Kafka.\n",
        "Para generar archivos Avro visualmente para ejemplos, utilizaremos: https://konbert.com/generator/avro\n",
        "De manera similar a Parquet, para manejar Avro con Pandas, necesitamos instalar el paquete `fastavro`:\n",
        "\n",
        "```bash\n",
        "pip install fastavro\n",
        "```\n",
        "\n",
        "Una vez instalada la dependencia, podemos trabajar con estos archivos de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o1l6JVoFYYT"
      },
      "outputs": [],
      "source": [
        "import fastavro\n",
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "with open('datos.avro', 'rb') as f:\n",
        "    avro_reader = fastavro.reader(f)\n",
        "    schema = avro_reader.writer_schema\n",
        "    df_avro = pd.DataFrame(avro_reader)\n",
        "\n",
        "# Escritura\n",
        "with open('datos_salida_pandas.avro', 'wb') as f:\n",
        "    data = df_avro.to_dict('records')\n",
        "    fastavro.writer(f, schema, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5haVLfj5FYYT"
      },
      "source": [
        "En resumen, dependiendo del caso de uso, será necesario utilizar un tipo de archivo u otro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bcS8PJRFYYT"
      },
      "source": [
        "## 3.7 Enlaces de Interés\n",
        "- Trabajar con CSV utilizando el módulo nativo de Python: https://docs.python.org/3/library/csv.html\n",
        "- Trabajar con JSON utilizando el módulo nativo de Python: https://docs.python.org/3/library/json.html\n",
        "- Parquet VS Avro: [https://airbyte.com/data-engineering-resources/parquet-vs-avro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffUKVtyVFYYT"
      },
      "source": [
        "# 4. MANIPULACIÓN Y ANÁLISIS DE DATOS CON PANDAS\n",
        "## 4.1 Introducción\n",
        "La manipulación y análisis de datos son componentes centrales en la ciencia e ingeniería de datos. Python ofrece poderosas librerías para estas tareas, siendo Pandas la más popular y ampliamente utilizada. En esta sección, exploraremos cómo utilizar Pandas para manipular y analizar datos de manera efectiva.\n",
        "El elemento principal en Pandas es el DataFrame. Esta es una estructura bidimensional (tabular) con columnas de diferentes tipos, similar a una hoja de cálculo o una tabla SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx8CoUHRFYYT"
      },
      "source": [
        "## 4.2 Carga e Inspección de Datos\n",
        "La primera etapa en el análisis de datos es la carga de estos desde diversas fuentes tales como CSV, JSON, Parquet o Avro. En este caso, veremos cómo leer archivos CSV.\n",
        "Como vimos en la sección anterior, la manera de cargar datos desde un CSV es simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we3BGlkGFYYT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKrk-MwvFYYT"
      },
      "source": [
        "Además, podemos obtener cierta información de nuestro DataFrame, por ejemplo, podemos extraer las primeras N filas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYQteyTdFYYT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "print(df.head(10)) # Por defecto, las primeras 5 filas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3thjzpGFYYU"
      },
      "source": [
        "Adicionalmente, podemos obtener más información que nos ayudará a describir nuestro DataFrame de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUEMcBJ6FYYU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "print(df.info()) # Información del DataFrame\n",
        "print(df.describe(include='all')) # Información descriptiva"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmkvT3_VFYYU"
      },
      "source": [
        "## 4.3 Selección, Filtrado y Creación\n",
        "La capacidad de seleccionar y filtrar es fundamental en el análisis e ingeniería de datos. En este caso, Pandas ofrece una solución sencilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KaAqzhwFYYU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "columna_firstname = df['firstname']\n",
        "print(columna_firstname)\n",
        "\n",
        "columnas_multiples = df[['firstname', 'lastname']]\n",
        "print(columnas_multiples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP3N082gFYYU"
      },
      "source": [
        "Para filtrar, la sintaxis es sencilla; simplemente debemos extender la utilizada previamente para seleccionar columnas. Por ejemplo, en Pandas, bastará con igualar el valor de la columna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKbuYPbTFYYU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "columna_filtrada = df[df['firstname'] == 'Kerry']\n",
        "print(columna_filtrada)\n",
        "\n",
        "# Output\n",
        "# id firstname   lastname              email\n",
        "# 0   1     Kerry  O'Connell  Kerry16@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwQ5iOLoFYYU"
      },
      "source": [
        "También podemos crear nuevas columnas a la vez que las completamos con valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wqE0X_lFYYU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "df['full_name'] = df['firstname'] + ' ' + df['lastname']\n",
        "df['full_name']\n",
        "\n",
        "# Output\n",
        "# 0     Kerry O'Connell\n",
        "# 1        Ethel Miller\n",
        "# 2       Willie Barton\n",
        "# 3          Ellis Lowe\n",
        "# 4      Raymond Miller\n",
        "# 5      Ellen Thompson\n",
        "# 6            Joe Rice\n",
        "# 7    Nathaniel Legros\n",
        "# 8     Maxine Schinner\n",
        "# 9        Tim Jacobson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1MfU3j4FYYV"
      },
      "source": [
        "Para modificar columnas, podemos operar sobre ellas de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGzldDgkFYYV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "df['full_name'] = df['firstname'] + ' ' + df['lastname']\n",
        "df['full_name'] = df['full_name'] + ' ' + df['email']\n",
        "df['full_name']\n",
        "\n",
        "# Output\n",
        "# 0           Kerry O'Connell Kerry16@gmail.com\n",
        "# 1            Ethel Miller Ethel14@hotmail.com\n",
        "# 2       Willie Barton Willie.Barton@gmail.com\n",
        "# 3             Ellis Lowe Ellis.Lowe@gmail.com\n",
        "# 4     Raymond Miller Raymond.Miller@gmail.com\n",
        "# 5          Ellen Thompson Ellen92@hotmail.com\n",
        "# 6                    Joe Rice Joe55@gmail.com\n",
        "# 7    Nathaniel Legros Nathaniel40@hotmail.com\n",
        "# 8        Maxine Schinner Maxine93@hotmail.com\n",
        "# 9              Tim Jacobson Tim92@hotmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GPQwLMoFYYV"
      },
      "source": [
        "## 4.4 Agrupación, Ordenación y Unión\n",
        "En cualquier tarea de procesamiento de datos, será necesario agrupar datos según sea necesario, así como ordenar e incluso combinar esos datos con otros utilizando técnicas de unión similares a los JOIN de SQL.\n",
        "Para agrupar, podemos referirnos a los clásicos `groupby` también presentes en SQL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGDpJpoTFYYV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "random_age = [random.randrange(25, 28, 1) for x in range(len(df))]\n",
        "\n",
        "df['age'] = random_age\n",
        "agrupado_edad = df.groupby('age')['firstname'].apply(list)\n",
        "print(agrupado_edad)\n",
        "\n",
        "# Output\n",
        "# age\n",
        "# 25              [Ethel, Ellen, Tim]\n",
        "# 26       [Kerry, Nathaniel, Maxine]\n",
        "# 27    [Willie, Ellis, Raymond, Joe]\n",
        "# Name: firstname, dtype: object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8ei2bSGFYYV"
      },
      "source": [
        "Ordenar columnas es algo más sencillo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9vxtY7cFYYV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lectura\n",
        "df = pd.read_csv('datos.csv')\n",
        "\n",
        "df_ordenado = df.sort_values(by='firstname', ascending=True)\n",
        "df_ordenado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRmBgjJxFYYV"
      },
      "source": [
        "Finalmente, tenemos las operaciones de unión mediante concatenación o join:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNJsqhCFFYYW"
      },
      "outputs": [],
      "source": [
        "# Concatenación vertical\n",
        "import pandas as pd\n",
        "\n",
        "df_1 = pd.read_csv('datos.csv')\n",
        "df_2 = pd.read_csv('datos.csv')\n",
        "\n",
        "df_concatenado = pd.concat([df_1, df_2])\n",
        "df_concatenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTyerZJRFYYW"
      },
      "outputs": [],
      "source": [
        "# Unión de dos dataframes utilizando una clave\n",
        "df_unido = pd.merge(df_1, df_2, on='id', how='inner')\n",
        "df_unido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxY0DDmgFYYW"
      },
      "source": [
        "Como se puede observar, en cuanto a sintaxis, ambos paquetes tienen operaciones similares y diferentes. Algunas con mejor legibilidad que otras, pero generalmente, es una sintaxis similar.\n",
        "En cuanto a características más relevantes, en Pandas, los DataFrames son mutables, lo que significa que cada operación modifica el DataFrame existente. Pandas es el estándar en la industria y tiene muchos más años y comunidad detrás, lo que lo convierte en una solución más fiable para proyectos en producción.\n",
        "La decisión de utilizar uno u otro dependerá del caso de uso, pero en última instancia del desarrollador."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}