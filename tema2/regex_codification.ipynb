{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfBeDkxw54FN"
   },
   "source": [
    "# 1 Codificaci칩n de caracteres y expresiones regulares\n",
    "La codificaci칩n de caracteres y las expresiones regulares son fundamentales en la miner칤a de texto y la b칰squeda de informaci칩n. La correcta codificaci칩n asegura que los caracteres se interpreten y visualicen adecuadamente, mientras que las expresiones regulares permiten buscar, filtrar y manipular texto basado en patrones espec칤ficos. Si no se controla la correcta codificaci칩n de caracteres, pueden surgir problemas como la aparici칩n de caracteres \"extra침os\" o signos de interrogaci칩n, lo que puede llevar a la p칠rdida de informaci칩n importante y errores en el procesamiento de datos. Adem치s, la falta de una codificaci칩n adecuada puede causar incompatibilidades entre diferentes sistemas y aplicaciones. Juntas, estas herramientas facilitan la extracci칩n eficiente y precisa de informaci칩n relevante de grandes vol칰menes de datos textuales, mejorando la calidad y la utilidad del an치lisis de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5A8_zRn3kdH"
   },
   "source": [
    "# 2 Codificaci칩n de caracteres\n",
    "## 2.1 Introducci칩n\n",
    "La codificaci칩n de caracteres es crucial en la miner칤a de texto, especialmente cuando se manejan fuentes internacionales o alfabetos diversos (latino, cir칤lico, chino, japon칠s, 치rabe, etc.). Una codificaci칩n incorrecta puede resultar en caracteres \"extra침os\" o signos de interrogaci칩n. Esta secci칩n cubre los fundamentos de la codificaci칩n, est치ndares como ASCII, Unicode y UTF-8, y sus implicaciones en la programaci칩n en Python. Se proporcionar치n ejemplos de lectura y escritura de archivos con diferentes codificaciones, destacando por qu칠 UTF-8 es el est치ndar en la mayor칤a de los proyectos modernos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoGALWY33kdI"
   },
   "source": [
    "## 2.2 ASCII, Unicode y UTF-8\n",
    "A lo largo del tiempo, se han desarrollado varios formatos de codificaci칩n, incluyendo ASCII, Unicode y UTF-8.\n",
    "- **ASCII**: Desarrollado en la d칠cada de 1960 para caracteres en ingl칠s, utiliza 7 bits e incluye 128 c칩digos para letras may칰sculas/min칰sculas, d칤gitos, signos de puntuaci칩n y caracteres de control. Por ejemplo, la letra \"A\" corresponde al 65, representado en binario como 01000001. Sin embargo, es insuficiente para caracteres con tildes u otros s칤mbolos.\n",
    "- **Unicode**: Busca unificar la representaci칩n de todos los alfabetos posibles, asignando un \"c칩digo de punto\" 칰nico a cada car치cter en casi todos los idiomas y sistemas de escritura, incluyendo caracteres latinos con tildes, ideogramas chinos y emojis.\n",
    "- **UTF-8**: Un esquema de codificaci칩n ampliamente adoptado que utiliza una cantidad variable de bytes (1 a 4) para representar cada car치cter Unicode. Es retrocompatible con ASCII (los primeros 128 s칤mbolos coinciden exactamente). Python utiliza UTF-8 por defecto en versiones recientes, evitando problemas de visualizaci칩n como \"츾췀\" en lugar de \"침\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-ebHBGU3kdI"
   },
   "source": [
    "## 2.3 Manejo de Codificaciones en Python\n",
    "Python permite especificar la codificaci칩n de un archivo al abrirlo para lectura o escritura. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IA872A9s3kdI"
   },
   "outputs": [],
   "source": [
    "# Lectura de un archivo con codificaci칩n UTF-8\n",
    "with open(\"test_utf8.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contenido = f.read()\n",
    "    print(contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fTvfej6D3kdJ"
   },
   "outputs": [],
   "source": [
    "# Escritura en un archivo con codificaci칩n ISO-8859-1\n",
    "with open(\"datos_latin1.csv\", \"w\", encoding=\"latin-1\") as f:\n",
    "    f.write(\"\"\"title, character\n",
    "char_1, 치\n",
    "char_2, 칠\n",
    "char_3, 칤\n",
    "char_4, 칩\n",
    "char_5, 칰\n",
    "char_6, 칲\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOqPK9Ws3kdJ"
   },
   "outputs": [],
   "source": [
    "# Lectura con codificaci칩n incorrecta que dar치 error\n",
    "with open(\"datos_latin1.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    contenido = f.read()\n",
    "    print(contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJSVbFu33kdJ"
   },
   "source": [
    "Si no se especifica el par치metro `encoding`, Python intentar치 utilizar la codificaci칩n predeterminada del sistema, lo que puede variar seg칰n la configuraci칩n regional del SO (Windows, Linux, macOS). Esto puede causar problemas al compartir c칩digo con personas en diferentes pa칤ses o servidores.\n",
    "\n",
    "Para la miner칤a de texto, es 칰til cargar los datos en un DataFrame para inspecci칩n y transformaci칩n. Tanto Pandas como Polars permiten especificar la codificaci칩n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whJYgR_o3kdJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pandas = pd.read_csv(\n",
    "    \"datos_latin1.csv\",\n",
    "    encoding=\"latin-1\",\n",
    "    sep=\",\",\n",
    "    header=0,  # La primera fila contiene los nombres de las columnas\n",
    ")\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvEbRHdR3kdJ"
   },
   "source": [
    "Si los datos se procesan incorrectamente, pueden aparecer caracteres como \"涌쪂". Tambi칠n es com칰n lidiar con varios alfabetos o idiomas simult치neamente, por lo que se recomienda unificar el procesamiento en UTF-8 y, si es necesario, utilizar bibliotecas para detectar el idioma, como langdetect, langid, o APIs como Google Translator o los nuevos LLMs como Gemini, OpenAI o Claude.\n",
    "\n",
    "Un ejemplo para unificar la codificaci칩n para el procesamiento de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vp2KeAIy3kdK"
   },
   "outputs": [],
   "source": [
    "def convertir_latin1_a_utf8(ruta_entrada, ruta_salida):\n",
    "    with open(ruta_entrada, \"r\", encoding=\"latin-1\") as f_in:\n",
    "        contenido = f_in.read()\n",
    "    with open(ruta_salida, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        f_out.write(contenido)\n",
    "\n",
    "\n",
    "convertir_latin1_a_utf8(\"datos_latin1.csv\", \"datos_utf-8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f36_kOAw3kdK"
   },
   "source": [
    "## 2.4 Identificaci칩n de Codificaciones con la Librer칤a chardet\n",
    "La librer칤a `chardet` es 칰til para identificar el tipo de codificaci칩n de un texto y se instala con pip. A continuaci칩n se muestra un ejemplo did치ctico de c칩mo identificar m칰ltiples tipos de codificaci칩n con esta librer칤a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BprEASXn3kdK"
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import os\n",
    "\n",
    "for f in os.listdir():\n",
    "    if \"test\" in f:\n",
    "        print(f)\n",
    "        with open(f, \"br\") as RF:\n",
    "            t = RF.read()\n",
    "            detection = chardet.detect(t)\n",
    "            print(detection)\n",
    "            encoding = detection[\"encoding\"]\n",
    "            print(t.decode(encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgZ5pSZj3kdK"
   },
   "source": [
    "# 3 Introducci칩n a las Expresiones Regulares\n",
    "Las expresiones regulares (regex) son herramientas poderosas para buscar, filtrar y manipular cadenas de texto basadas en patrones espec칤ficos. Son esenciales en la miner칤a de texto para tareas como limpieza, normalizaci칩n y extracci칩n de informaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJXQXLmN3kdK"
   },
   "source": [
    "## 3.1 Estructura de las Expresiones Regulares\n",
    "- **Caracteres especiales**:\n",
    "  - `.`: Coincide con cualquier car치cter excepto el salto de l칤nea.\n",
    "  - `^` y `$`: Delimitan el inicio y fin de la l칤nea.\n",
    "  - `*`, `+`, `?`: Modificadores de repetici칩n.\n",
    "  - `[]`: Define clases de caracteres, como `[0-9]` para cifras.\n",
    "  - `\\d`, `\\w`, `\\s`: Atajos para d칤gitos, caracteres de palabra y espacios en blanco.\n",
    "- **Agrupaciones y rangos**:\n",
    "  - `( )`: Agrupa un patr칩n y permite capturar resultados.\n",
    "  - `{n,m}`: Define un rango de repeticiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0JMKb9g3kdK"
   },
   "source": [
    "## 3.2 Uso B치sico en Python\n",
    "El m칩dulo `re` de Python proporciona funciones esenciales:\n",
    "- `re.match(patron, cadena)`: Busca al principio del string.\n",
    "- `re.search(patron, cadena)`: Busca la primera aparici칩n del patr칩n.\n",
    "- `re.findall(patron, cadena)`: Devuelve una lista con todas las apariciones.\n",
    "- `re.sub(patron, reemplazo, cadena)`: Reemplaza todas las apariciones del patr칩n.\n",
    "- `re.split(patron, cadena)`: Divide el string utilizando el patr칩n como delimitador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFu2Z3o93kdK"
   },
   "source": [
    "## 3.3 Ejemplos Pr치cticos\n",
    "### Encontrar Hashtags en Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzLqfnxw3kdK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "regex_hashtag = re.compile(r\"#\\w+\")\n",
    "tweets = [\n",
    "    \"Amo la ciencia de datos! #DataScience #Python\",\n",
    "    \"Me encanta INSD en la U-Tad! #WorkHard #Focus\",\n",
    "]\n",
    "\n",
    "df_pandas = pd.DataFrame({\"text\": tweets})\n",
    "df_pandas[\"hashtags\"] = df_pandas[\"text\"].str.findall(regex_hashtag)\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N37K3HhZ3kdK"
   },
   "source": [
    "### Limpiar Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHh-f_Kl3kdK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    texto_limpio = re.sub(\n",
    "        r\"\\.{2,}\", \".\", texto\n",
    "    )  # Eliminar signos de puntuaci칩n repetidos\n",
    "    texto_limpio = re.sub(\n",
    "        r\"\\s{2,}\", \" \", texto_limpio\n",
    "    )  # Reemplazar m칰ltiples espacios por uno\n",
    "    return texto_limpio\n",
    "\n",
    "\n",
    "tweets = [\n",
    "    \"Amo    la    ciencia... de datos! #DataScience #Python\",\n",
    "    \"Me    encanta... INSD en      la U-Tad! #WorkHard #Focus\",\n",
    "]\n",
    "df_pandas = pd.DataFrame({\"texto original\": tweets})\n",
    "df_pandas[\"texto limpio\"] = df_pandas[\"texto original\"].apply(limpiar_texto)\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rPPBQ163kdK"
   },
   "source": [
    "### Extraer N칰meros de Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Wv7skli3kdK"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "exp_serie = re.compile(r\"[A-Z]{3}-\\d{4}-[A-Z]{3}\")\n",
    "lineas = [\n",
    "    \"Producto: ABC-1234-XYZ fecha: 2022-10-10\",\n",
    "    \"ID: ZZZ-9999-AAA   Producto: Ordenador\",\n",
    "    \"Texto irrelevante: AAA 3333 BBB\",\n",
    "]\n",
    "\n",
    "\n",
    "def extract_serial(line):\n",
    "    match = exp_serie.findall(line)\n",
    "    return match if match else None\n",
    "\n",
    "\n",
    "df_pandas = pd.DataFrame({\"text\": lineas})\n",
    "df_pandas[\"serial number\"] = df_pandas[\"text\"].apply(extract_serial)\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ50-y2V3kdK"
   },
   "source": [
    "# 4: Librer칤as re y regex en Python\n",
    "## 4.1 Introducci칩n\n",
    "En miner칤a de texto, las expresiones regulares son esenciales para la limpieza y extracci칩n de informaci칩n. Aunque el m칩dulo `re` de Python es 칰til, la librer칤a `regex` ofrece funcionalidades adicionales y mejoras, especialmente para documentos con caracteres poco usuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmYpMx1y3kdK"
   },
   "source": [
    "## 4.2 Limitaciones de re\n",
    "El m칩dulo `re` tiene algunas limitaciones:\n",
    "- **Lookbehind fijo**: `re` requiere que la longitud de la subexpresi칩n en lookbehind sea fija.\n",
    "- **Compatibilidad**: No implementa todos los aspectos de la sintaxis de expresiones regulares de otros lenguajes.\n",
    "- **Rendimiento**: Puede ser menos eficiente en patrones complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brPrD_Ej3kdK"
   },
   "source": [
    "## 4.3 Diferencias entre re y regex\n",
    "La librer칤a `regex` es un reemplazo mejorado de `re`, ofreciendo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1na-WHa_3kdK"
   },
   "source": [
    "### 4.3.1 Lookbehind\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJJWdcF63kdL"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "pat = regex.compile(r\"(?<=\\d+)car\")\n",
    "texto = \"123car 55car 9999car\"\n",
    "resultados = pat.findall(texto)\n",
    "print(\"Coincidencias (regex):\", resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlDk8ohS3kdL"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `(?<=\\d+)`: Este es un lookbehind que busca una secuencia de uno o m치s d칤gitos (`\\d+`) antes de la palabra \"car\". En `regex`, el lookbehind puede tener longitud variable.\n",
    "- `car`: La palabra que queremos encontrar despu칠s de los d칤gitos.\n",
    "\n",
    "**Resultado**: Encuentra todas las ocurrencias de \"car\" que est치n precedidas por uno o m치s d칤gitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_jkyupn3kdL"
   },
   "source": [
    "### 4.3.2 Soporte Unicode avanzado\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4r90g-y3kdL"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "pattern_emoji = regex.compile(r\"\\p{Extended_Pictographic}+\")\n",
    "texto_emojis = \"Hoy me siento feliz 游땏 y triste 游땩 a la vez.\"\n",
    "emojis = pattern_emoji.findall(texto_emojis)\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-em0bTw3kdL"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `\\p{Extended_Pictographic}`: Esta es una propiedad Unicode que coincide con caracteres pictogr치ficos extendidos, como emojis.\n",
    "- `+`: Modificador que indica que queremos encontrar una o m치s ocurrencias consecutivas de emojis.\n",
    "\n",
    "**Resultado**: Encuentra todos los emojis en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV1rPfaH3kdL"
   },
   "source": [
    "### 4.3.3 Recursividad y anidaci칩n\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cibyu3JP3kdL"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "par_patron = regex.compile(\n",
    "    r\"\"\"\n",
    "    \\(\n",
    "       (?: [^()]+ | (?R) )*\n",
    "    \\)\n",
    "\"\"\",\n",
    "    regex.VERBOSE,\n",
    ")\n",
    "\n",
    "texto_par = \"Aqu칤 (tenemos (un ejemplo) de (anidaci칩n (compleja))) y (otro).\"\n",
    "encontrados = par_patron.findall(texto_par)\n",
    "print(\"Par칠ntesis anidados:\", encontrados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5r3Iww_3kdL"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `\\(` y `\\)`: Coinciden con los caracteres de par칠ntesis de apertura y cierre.\n",
    "- `(?: [^()]+ | (?R) )*`: Esta es una expresi칩n regular recursiva:\n",
    "  - `[^()]+`: Coincide con cualquier secuencia de caracteres que no sean par칠ntesis.\n",
    "  - `(?R)`: Llama recursivamente a la expresi칩n regular completa, permitiendo la coincidencia de par칠ntesis anidados.\n",
    "- `regex.VERBOSE`: Permite escribir la expresi칩n regular en m칰ltiples l칤neas con comentarios para mayor claridad.\n",
    "\n",
    "**Resultado**: Encuentra todas las secuencias de par칠ntesis anidados en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGgo1B9_3kdL"
   },
   "source": [
    "## 4.4 Casos de uso con re y regex\n",
    "### 4.4.1 Obtener valores num칠ricos con separadores\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Lb6PO53kdL"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "pattern_numerico = regex.compile(r\"(?<!\\w)(\\d+(?:[.,]\\d+)?)(?!\\w)\")\n",
    "texto_mixto = \"Precio: 45,67 euros, o tal vez 100.50 USD, etc. Valor2=123\"\n",
    "coinc = pattern_numerico.findall(texto_mixto)\n",
    "print(coinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c3QrjvD3kdL"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `(?<!\\w)`: Lookbehind negativo que asegura que el n칰mero no est칠 precedido por un car치cter de palabra.\n",
    "- `\\d+`: Coincide con una secuencia de uno o m치s d칤gitos.\n",
    "- `(?:[.,]\\d+)?`: Grupo no capturante que coincide con un punto o una coma seguido de uno o m치s d칤gitos. El `?` indica que esta parte es opcional.\n",
    "- `(?!\\w)`: Lookahead negativo que asegura que el n칰mero no est칠 seguido por un car치cter de palabra.\n",
    "\n",
    "**Resultado**: Encuentra todos los n칰meros con separadores decimales en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFDXXOyc3kdL"
   },
   "source": [
    "### 4.4.2 Extracci칩n de subdominios\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBLgDMUR3kdL"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "dom_pat = regex.compile(r\"(?<=https?://)([\\w.-]+)\\.(\\p{Letter}{2,})(?=/?)\")\n",
    "test_urls = [\n",
    "    \"https://sub.example.com/path/to/file\",\n",
    "    \"http://mydomain.org/index.html\",\n",
    "    \"https://xxx.co/short\",\n",
    "]\n",
    "\n",
    "for url in test_urls:\n",
    "    res = dom_pat.search(url)\n",
    "    if res:\n",
    "        print(f\"URL: {url}\")\n",
    "        print(\" Dominio principal:\", res.group(1))\n",
    "        print(\" TLD:\", res.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAbK6oXP3kdM"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `(?<=https?://)`: Lookbehind que asegura que la coincidencia est칠 precedida por \"http://\" o \"https://\".\n",
    "- `([\\w.-]+)`: Grupo que coincide con una secuencia de caracteres de palabra, puntos o guiones.\n",
    "- `\\.`: Coincide literalmente con un punto.\n",
    "- `\\p{Letter}{2,}`: Propiedad Unicode que coincide con dos o m치s letras.\n",
    "- `(?=/?)`: Lookahead que asegura que la coincidencia est칠 seguida opcionalmente por una barra.\n",
    "\n",
    "**Resultado**: Extrae el dominio principal y la TLD de las URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSeeWFTA3kdM"
   },
   "source": [
    "### 4.4.3 Detecci칩n de texto espec칤fico\n",
    "#### Ejemplo con regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddbFg1EL3kdM"
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "pattern_cyr = regex.compile(r\"\\p{Script=Cyrillic}+\")\n",
    "sample_text = \"Texto con 햨햦햦햩햩햦혡햟 y lat칤n mezclado\"\n",
    "found_cyr = pattern_cyr.findall(sample_text)\n",
    "print(\"Cir칤lico:\", found_cyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hx1E30Fr3kdM"
   },
   "source": [
    "**Explicaci칩n**:\n",
    "- `\\p{Script=Cyrillic}`: Propiedad Unicode que coincide con caracteres del alfabeto cir칤lico.\n",
    "- `+`: Modificador que indica que queremos encontrar una o m치s ocurrencias consecutivas de caracteres cir칤licos.\n",
    "\n",
    "**Resultado**: Encuentra todas las secuencias de caracteres cir칤licos en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD-KETt33kdM"
   },
   "source": [
    "## 4.5 Cu치ndo usar re o regex\n",
    "La elecci칩n entre `re` y `regex` depende de:\n",
    "- **Patrones complejos**: `regex` es mejor para anidamiento o lookbehind variable.\n",
    "- **Rendimiento**: `regex` puede ser m치s eficiente en ciertos casos.\n",
    "- **Unicode avanzado**: `regex` maneja mejor las propiedades Unicode.\n",
    "\n",
    "Ambas librer칤as se integran bien con pandas y polars para la manipulaci칩n tabular del texto, y son 칰tiles antes de pasar a librer칤as de procesamiento de lenguaje natural como NLTK o spaCy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}